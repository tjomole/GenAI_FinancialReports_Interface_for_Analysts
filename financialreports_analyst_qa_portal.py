# -*- coding: utf-8 -*-
"""FinancialReports_Analyst_QA_Portal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ThQcdhCXiYqWQ5rNBj4yq-4JwvKw4lRb

## Overview

**Problem statement**: Use Gen AI to develop search and chat functionality which pulls the information from a set of documents and provides summarized.

**Model structure**: the key steps in the model construction are: Set up/Create questions set database → Upload PDF and generate embeddings → Summarize the Contents → Questions box → Retrieval of pre-defined Questions → Get answers to the pre-defined questions.

### Main Steps:

a. Upload PDF and generate embeddings
b. Summarize the Contents
c. Questions box for Analyst
d. Retrival of pre-defined Questions
e. Get answer to the pre-defined questions.

#### Credits:

  - HuggingFace: Configuration reference at https://huggingface.co/docs/hub/spaces-config-reference

  - Gradio API

  - LangChain: lekkalar/chatgpt-for-pdf-using-langchain-gpt4-chromadb-prompttemplate-tabs-dataframe-ocrmypdf-sqlite-csv

Relevant Applications/Libraries
"""

!pip install openai
!pip install tiktoken
!pip install chromadb
!pip install langchain_community
!pip install --upgrade gradio
!pip install pytesseract
!pip install faiss-cpu
!pip install ocrmypdf
!pip install textract
!pip install pypdf2
!pip install unstructured
!pip install unstructured[local-inference]
!pip install ghostscript

!jupyter nbconvert --execute lab_name.ipynb

# Imports
import gradio as gr
import sqlite3
import os
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
import ocrmypdf
import pandas as pd
import PyPDF2
from langchain.document_loaders import PyPDFLoader
from langchain.document_loaders import PyPDFDirectoryLoader
from langchain.document_loaders import UnstructuredFileLoader
from langchain.document_loaders import TextLoader
from langchain.document_loaders import Docx2txtLoader
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.document_loaders import OnlinePDFLoader
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma # for vectorization
from langchain.chains import RetrievalQA # to converse with chatGPT
from langchain.chat_models import ChatOpenAI
from langchain import PromptTemplate

"""### Set up/Create Questions set DB"""

# Create questions db
def create_db_connection():
    DB_FILE = "/content/questionset.db"
    connection = sqlite3.connect(DB_FILE,check_same_thread=False)
    return connection

def create_sqlite_table(connection):
    print("*****Entered the create_sqlite_table method*****")
    cursor = connection.cursor()
    # Create table if it doesn't already exist
    try:
        data = f'SELECT * FROM questions'
        cursor.execute(data)
        cursor.fetchall()

    except sqlite3.OperationalError:
        cursor.execute(
        '''
        CREATE TABLE questions (document_type TEXT NOT NULL, questionset_tag TEXT NOT NULL, field TEXT NOT NULL, question TEXT NOT NULL)
        ''')
        print("*****questions table has been created******")
    connection.commit()

# Load questions - Financial Summary and Ratios
def load_master_questionset_into_sqlite(connection):
    create_sqlite_table(connection)
    cursor = connection.cursor()
    #Check to make sure the masterlist has not been loaded already.
    masterlist_for_Ratios_count = cursor.execute("Select COUNT(document_type) from questions where document_type=? and questionset_tag=?",("Ratios","masterlist",),).fetchone()[0]
    if masterlist_for_Ratios_count == 0:
        print("Ratios masterlist has not yet been loaded, proceeding to load.")
        #Create a list of questions around the relevant fields of a Financial Ratios(Ratios) document
        fieldListForRatios, queryListForRatios = create_field_and_question_list_for_Ratios()
        #Create a list of questions around the relevant fields of FINANCIAL SUMMARY document
        fieldListForFinancialSummary, queryListForFinancialSummary = create_field_and_question_list_for_Financial_Summary()
        #Loop through the list and add them into the questions table
        i = 0
        print("*****Entered the load master question set method*****")
        while i < len(queryListForRatios):
            cursor.execute("INSERT INTO questions(document_type, questionset_tag, field, question) VALUES(?,?,?,?)", ["Ratios", "masterlist", fieldListForRatios[i], queryListForRatios[i]])
            i = i+1
        i = 0
        while i < len(queryListForFinancialSummary):
            cursor.execute("INSERT INTO questions(document_type, questionset_tag, field, question) VALUES(?,?,?,?)", ["Financial Summary", "masterlist", fieldListForFinancialSummary[i], queryListForFinancialSummary[i]])
            i = i+1
        connection.commit()
    total_questions = cursor.execute("Select COUNT(document_type) from questions").fetchone()[0]
    print("*******Total number of questions in the DB:", total_questions)

# Create questions Lists
def create_field_and_question_list_for_Ratios():
    #Create a list of questions around the relevant fields of a Financial Ratios(Ratios) document
    query1 = "What is the Return on Equity (ROE) ratio?"
    field1 = "ROE Ratio"
    query2 = "What is the Return on Assets (ROA) Ratio?"
    field2 = "ROA Ratio"
    query3 = "What is the Efficiency Ratio?"
    field3 = "Efficiency Ratio"
    query4 = "What is the Tier 1 Capital Ratio?"
    field4 = "Tier 1 Capital Ratio"
    query5 = "What is the Liquidity Coverage Ratio?"
    field5 = "Liquidity Coverage Ratio"
    query6 = "What is the Dividend Payout Ratio?"
    field6 = "Dividend Payout Ratio"
    query7 = "What is the Debt to Equity Ratio?"
    field7 = "Debt to Equity Ratio"
    query8 = "What is the Debt to Assets Ratio?"
    field8 = "Debt to Assets Ratio"
    queryList = [query1, query2, query3, query4, query5, query6, query7, query8]
    fieldList = [field1, field2, field3, field4, field5, field6, field7, field8]
    return fieldList, queryList

def create_field_and_question_list_for_Financial_Summary():
    #Create a list of questions around the relevant fields of a Financial SUMMARY document
    query1 = "What is the Net Interest Income?"
    field1 = "Net Interest Income"
    query2 = "What is the Non Interest Income?"
    field2 = "Non Interest Income"
    query3 = "What is the Total Revenue?"
    field3 = "Total Revenue"
    query4 = "What is the Net Income?"
    field4 = "Net Income"
    query5 = "What is the Total Assets?"
    field5 = "Assets"
    query6 = "What is the Total Loans?"
    field6 = "Loans"
    query7 = "What is the Total Deposits?"
    field7 = "Deposits"
    query8 = "What is the Total Equity?"
    field8 = "Total Equity"
    query9 = "What is the Total Liabilities?"
    field9 = "Total Liabilities"
    queryList = [query1, query2, query3, query4, query5, query6, query7, query8, query9]
    fieldList = [field1, field2, field3, field4, field5, field6, field7, field8, field9]
    return fieldList, queryList

# Connect to and retrieve from DB
def retrieve_document_type_and_questionsettag_from_sqlite():
    connection = create_db_connection()
    load_master_questionset_into_sqlite(connection)
    cursor = connection.cursor()
    rows = cursor.execute("SELECT document_type, questionset_tag FROM questions order by document_type, upper(questionset_tag)").fetchall()
    print("Number of rows retrieved from DB:",len(rows))
    list_for_dropdown = []
    for i in rows:
      entries_in_row = list(i)
      concatenated_value = entries_in_row[0]+ ":" + entries_in_row[1]
      if concatenated_value in list_for_dropdown:
          print("Value already in the list:", concatenated_value)
      else:
          list_for_dropdown.append(concatenated_value)
          print(concatenated_value)

    print("Number of unique entries found in the DB:",len(list_for_dropdown))
    connection.close()
    return gr.Dropdown.update(choices=list_for_dropdown,value=list_for_dropdown[0])


def retrieve_fields_and_questions(dropdownoption):
    #dropdownoption will be in the documentType:questionSetTag format
    print("dropdownoption is:", dropdownoption)
    splitwords = dropdownoption.split(":")
    connection = create_db_connection()
    cursor = connection.cursor()
    fields_and_questions = cursor.execute("SELECT document_type,field, question FROM questions where document_type=? and questionset_tag=?",(splitwords[0],splitwords[1],),).fetchall()
    connection.close()
    return pd.DataFrame(fields_and_questions, columns=["documentType","field", "question"])

def add_questionset(data, document_type, tag_for_questionset):
# loop through the rows using iterrows()
    connection = create_db_connection()
    create_sqlite_table(connection)
    cursor = connection.cursor()
    for index, row in data.iterrows():
        cursor.execute("INSERT INTO questions(document_type, questionset_tag, field, question) VALUES(?,?,?,?)", [document_type, tag_for_questionset, row['field'], row['question']])
    connection.commit()
    connection.close()

"""Connect to OpenAI, load pdf document(s), and generate embeddings"""

def load_pdf_and_generate_embeddings(pdf_doc, relevant_pages):
    OPENAI_API_KEY = "your-OpenAI-API-key"  # Set the API key directly

    # OCR Conversion - skips conversion of pages that already contain text
    pdf_doc = ocr_converter(pdf_doc)

    # Load the pdf file
    loader = OnlinePDFLoader(pdf_doc)
    pages = loader.load_and_split()
    print('pages loaded:', len(pages))

    # Create an instance of OpenAIEmbeddings, passing the API key directly
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

    pages_to_be_loaded = []

    if relevant_pages:
        page_numbers = relevant_pages.split(",")
        if len(page_numbers) != 0:
            for page_number in page_numbers:
                if page_number.isdigit():
                    pageIndex = int(page_number) - 1
                    if pageIndex >= 0 and pageIndex < len(pages):
                        pages_to_be_loaded.append(pages[pageIndex])

    # In the scenario where none of the page numbers supplied exist in the PDF, revert to using the entire PDF.
    if len(pages_to_be_loaded) == 0:
        pages_to_be_loaded = pages.copy()

    # Create a vector store using the Chroma class, which takes the documents and the embeddings instance
    vectordb = Chroma.from_documents(pages_to_be_loaded, embedding=embeddings)

    # Create the bot using the RetrievalQA class, passing the API key directly to ChatOpenAI
    global pdf_qa

    prompt_template = """
    Use the following pieces of context to answer the question at the end. If you do not know the answer, just return N/A. If you encounter a date, return it in mm/dd/yyyy format.

    {context}

    Question: {question}
    Return just the answer. Provide the answer in the JSON format and extract the key from the question:
    """
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    chain_type_kwargs = {"prompt": PROMPT}

    # Pass the API key directly to the ChatOpenAI instance
    pdf_qa = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(temperature=0, model_name="gpt-4", openai_api_key=OPENAI_API_KEY),
        chain_type="stuff",
        retriever=vectordb.as_retriever(search_kwargs={"k": 5}),
        chain_type_kwargs=chain_type_kwargs,
        return_source_documents=False
    )

    return "Ready"


def load_csv_and_store_questionset_into_sqlite(csv_file, document_type, tag_for_questionset):
    print('document type is:', document_type)
    print('tag_for_questionset is:', tag_for_questionset)

    if tag_for_questionset:
        if document_type:
            data = pd.read_csv(csv_file.name)
            add_questionset(data, document_type, tag_for_questionset)
            responseString = "Task Complete. Uploaded {} fields and the corresponding questions into the Database for {}:{}".format(data.shape[0], document_type, tag_for_questionset)
            return responseString
        else:
            return "Please select the Document Type and provide a name for the Question Set"


def answer_predefined_questions(document_type_and_questionset):
    print('chosen document_type_and_questionset:', document_type_and_questionset)
    option_chosen = document_type_and_questionset.split(":")
    document_type = option_chosen[0]
    question_set = option_chosen[1]
    fields = []
    questions = []
    responses = []

    connection = create_db_connection()
    cursor = connection.cursor()

    if document_type is not None and question_set is not None:
        # Given the document_type and questionset_tag, retrieve the corresponding fields and questions from the database
        rows = cursor.execute("SELECT field, question FROM questions where document_type=? and questionset_tag=?",
                              (document_type, question_set,)).fetchall()
        for i in rows:
            entries_in_row = list(i)
            fields.append(entries_in_row[0])
            questions.append(entries_in_row[1])
            responses.append(pdf_qa.run(entries_in_row[1]))
    else:
        return "Please choose your Document Type:QuestionSet"

    return pd.DataFrame({"Field": fields, "Question to gpt-4": questions, "Response from gpt-4": responses})


def ocr_converter(input_file):
    image_pdf = input_file.name
    ocrmypdf.ocr(image_pdf, image_pdf, skip_text=True, language="eng")
    ocrmypdf.ocr(image_pdf, image_pdf, redo_ocr=True, language="eng")
    return image_pdf


def answer_query(query):
    question = query
    return pdf_qa.run(question)

"""Use Gradio to create interface/chat sessions for Analyst to use."""

!pip install --upgrade gradio

"""
The section will create the "portal for analyst to interface (question and response) with the portal."""

css = """
#col-container {max-width: 700px; margin-left: auto; margin-right: auto;}
"""

title = """
<div style="text-align: center;max-width: 700px;">
    <h1>Chatbot for PDFs - GPT-4</h1>
    <p style="text-align: center;">Upload a .PDF, click the "Upload PDF and generate embeddings" button, <br />
    Wait for the Status to show Ready. You can choose to get answers to the pre-defined question set OR ask your own question <br />
    The app is built on GPT-4 and leverages PromptTemplate</p>
</div>
"""

# OpenAI API Key
OPENAI_API_KEY = "your-OpenAI-API-key"  # Set the API key directly

# Gradio Blocks UI setup
with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as demo:
    with gr.Column(elem_id="col-container"):
        gr.HTML(title)

    with gr.Tab("Chatbot"):
        with gr.Column():
            pdf_doc = gr.File(label="Load a pdf", file_types=['.pdf'], type='filepath')
            relevant_pages = gr.Textbox(label="*Optional - List comma-separated page numbers to load or leave this field blank to use the entire PDF")

            with gr.Row():
                status = gr.Textbox(label="Status", placeholder="", interactive=False)
                load_pdf = gr.Button("Upload PDF and generate embeddings")

            with gr.Row():
                input = gr.Textbox(label="Type in your question")
                output = gr.Textbox(label="Answer")
                submit_query = gr.Button("Submit your own question to GPT-4")

            with gr.Row():
                questionsets = gr.Dropdown(label="Pre-defined Question Sets stored in the DB", choices=[])
                load_questionsets = gr.Button("Retrieve Pre-defined Question Sets from DB")
                fields_and_questions = gr.Dataframe(label="Fields and Questions in the chosen Question Set")
                load_fields_and_questions = gr.Button("Retrieve Pre-defined Questions from the DB for the chosen QuestionSet")

            with gr.Row():
                answers = gr.Dataframe(label="Answers to Predefined Question set")
                answers_for_predefined_question_set = gr.Button("Get GPT-4 answers to the chosen pre-defined question set")

    with gr.Tab("Upload Question Set"):
        with gr.Column():
            document_types = ["BOA_Report", "WF_Report"]
            document_type_for_questionset = gr.Dropdown(choices=document_types, label="Select the Document Type")
            tag_for_questionset = gr.Textbox(label="Please provide a name for the question set. Ex: rwikd-dot-basic-questionset-20230707.")
            csv_file = gr.File(label="Load a csv - 2 columns with the headers as field, question", file_types=['.csv'], type='filepath')

            with gr.Row():
                status_for_loading_csv = gr.Textbox(label="Status", placeholder="", interactive=False)
                load_csv = gr.Button("Upload data into the database")

    # Gradio function linkages
    load_pdf.click(load_pdf_and_generate_embeddings, inputs=[pdf_doc, relevant_pages], outputs=status)
    load_csv.click(load_csv_and_store_questionset_into_sqlite, inputs=[csv_file, document_type_for_questionset, tag_for_questionset], outputs=status_for_loading_csv)

    load_questionsets.click(retrieve_document_type_and_questionsettag_from_sqlite, outputs=questionsets)
    load_fields_and_questions.click(retrieve_fields_and_questions, inputs=[questionsets], outputs=fields_and_questions)
    answers_for_predefined_question_set.click(answer_predefined_questions, inputs=[questionsets], outputs=answers)

# Launch the demo with debug mode enabled
demo.launch(share=True, debug=False)